

<h1 align="center">HeartSpeak AI</h1>

<p align="center">
  <strong>Speak Without Words</strong><br/>
  An AI-powered multimodal communication platform for speech-impaired individuals
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Next.js-16.1-black?style=flat-square&logo=next.js" alt="Next.js"/>
  <img src="https://img.shields.io/badge/React-19-blue?style=flat-square&logo=react" alt="React"/>
  <img src="https://img.shields.io/badge/Node.js-Express-green?style=flat-square&logo=node.js" alt="Node.js"/>
  <img src="https://img.shields.io/badge/Python-FastAPI-teal?style=flat-square&logo=python" alt="Python"/>
  <img src="https://img.shields.io/badge/AI-Gemini%20%7C%20GPT--4o-orange?style=flat-square&logo=google" alt="AI"/>
  <img src="https://img.shields.io/badge/WebRTC-P2P-red?style=flat-square&logo=webrtc" alt="WebRTC"/>
</p>

---

## ğŸŒŸ Overview

**HeartSpeak AI** transforms non-verbal expressionsâ€”facial expressions, gestures, drawings, and patternsâ€”into meaningful emotional communication. This platform enables mute individuals to "speak" their hearts fluently through AI-powered emotion recognition and translation.

> *"Communication from the heart, not the mouth."*

### ğŸ¯ Core Vision

Traditional AAC (Augmentative and Alternative Communication) apps focus on building sentences word by word. HeartSpeak takes a revolutionary **emotion-first approach**, capturing and translating feelings into natural, contextual language.

---

## âœ¨ Key Features

### ğŸ¥ 1. Visual Emotion Recognition Video Call
Real-time video calling where facial expressions and gestures are analyzed and converted to emotional text for the other participant.

- **Real-time facial analysis** using MediaPipe + Gemini AI
- **Micro-expression detection** capturing nuanced emotions
- **Natural language generation** ("Your friend seems thoughtful and mildly concerned")
- **WebRTC peer-to-peer** video streaming

### ğŸ¨ 2. Pattern-Based Emotional Language
Create visual patterns (drawings, colors, shapes) that represent emotions. AI learns personal associations.

- **Personal pattern dictionary** unique to each user
- **Visual emotion mapping** (spirals â†’ confusion, warm gradients â†’ comfort)
- **Historical symbol integration** (semaphore, universal visual languages)
- **Create "secret codes"** with friends and family

### ğŸ’¬ 3. Heart-to-Heart Chat System
Emotion-first messaging where users select feelings, intensity, and contextâ€”AI generates natural text.

- **Emotion composer** with primary/secondary emotions
- **Intensity slider** from subtle to overwhelming
- **Context layers** (body sensations, memory links)
- **Auto-generated emotion gradients** and visual art

### ğŸ¤– 4. Personal Emotion Avatar
An AI companion that learns your unique emotional patterns and communication style.

- **Learns your emotional vocabulary** over time
- **Relationship-aware** suggestions (different tone for family vs friends)
- **Proactive insights** ("You haven't connected with Mom in 2 weeks...")
- **Authentic voice** that maintains your personality

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HeartSpeak AI                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Client     â”‚â—„â”€â”€â–ºâ”‚   Server     â”‚â—„â”€â”€â–ºâ”‚   AI Service     â”‚  â”‚
â”‚  â”‚  (Next.js)   â”‚    â”‚  (Node.js)   â”‚    â”‚   (FastAPI)      â”‚  â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚                  â”‚  â”‚
â”‚  â”‚ â€¢ Dashboard  â”‚    â”‚ â€¢ REST API   â”‚    â”‚ â€¢ Gemini AI      â”‚  â”‚
â”‚  â”‚ â€¢ Video Call â”‚    â”‚ â€¢ Socket.io  â”‚    â”‚ â€¢ GPT-4o         â”‚  â”‚
â”‚  â”‚ â€¢ Chat       â”‚    â”‚ â€¢ WebRTC Sig â”‚    â”‚ â€¢ MediaPipe      â”‚  â”‚
â”‚  â”‚ â€¢ Patterns   â”‚    â”‚ â€¢ MongoDB    â”‚    â”‚ â€¢ LangChain      â”‚  â”‚
â”‚  â”‚ â€¢ Avatar     â”‚    â”‚ â€¢ Auth/JWT   â”‚    â”‚ â€¢ Emotion Chains â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                         WebSocket + REST                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
HackDay/
â”œâ”€â”€ ğŸ“ client/                 # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/               # App Router pages
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/     # Protected dashboard routes
â”‚   â”‚   â”‚   â”œâ”€â”€ signin/        # Authentication
â”‚   â”‚   â”‚   â””â”€â”€ test-call/     # Video call testing
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/     # Dashboard UI
â”‚   â”‚   â”‚   â”œâ”€â”€ landing/       # Landing page sections
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/            # Reusable UI components
â”‚   â”‚   â”‚   â””â”€â”€ video-call/    # Video call components
â”‚   â”‚   â”œâ”€â”€ hooks/             # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ lib/               # Utilities & API client
â”‚   â”‚   â”œâ”€â”€ store/             # Zustand state management
â”‚   â”‚   â””â”€â”€ types/             # TypeScript types
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ğŸ“ Server/                 # Node.js Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ modules/       # Feature modules
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Auth/      # Authentication
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ User/      # User management
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Video/     # Video call logic
â”‚   â”‚   â”‚   â”œâ”€â”€ socket/        # WebSocket handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ services/      # External service integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ middlewares/   # Express middlewares
â”‚   â”‚   â”‚   â””â”€â”€ utils/         # Utility functions
â”‚   â”‚   â”œâ”€â”€ app.ts             # Express app setup
â”‚   â”‚   â””â”€â”€ server.ts          # Entry point + Socket.io
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ğŸ“ AI-Service/             # Python AI Service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/            # API endpoints
â”‚   â”‚   â”œâ”€â”€ agents/            # LangChain agents
â”‚   â”‚   â”œâ”€â”€ chains/            # LangChain chains
â”‚   â”‚   â”œâ”€â”€ memory/            # Conversation memory
â”‚   â”‚   â”œâ”€â”€ services/          # AI service wrappers
â”‚   â”‚   â””â”€â”€ main.py            # FastAPI entry point
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ shared/                 # Shared resources
â”‚   â”œâ”€â”€ constants/             # Emotion definitions, colors
â”‚   â””â”€â”€ types/                 # Shared TypeScript types
â”‚
â”œâ”€â”€ idea.md                    # Project vision & concept
â”œâ”€â”€ pipeline.md                # Complete architecture docs
â””â”€â”€ README.md                  # This file
```

---

## ğŸ› ï¸ Tech Stack

### Frontend (`client/`)
| Technology | Purpose |
|------------|---------|
| **Next.js 16** | React framework with App Router |
| **React 19** | UI library |
| **TailwindCSS 4** | Utility-first styling |
| **Framer Motion** | Animations |
| **Zustand** | State management |
| **Socket.io-client** | Real-time communication |
| **simple-peer** | WebRTC wrapper |
| **Lucide React** | Icons |

### Backend (`Server/`)
| Technology | Purpose |
|------------|---------|
| **Express.js** | Web framework |
| **TypeScript** | Type safety |
| **MongoDB/Mongoose** | Database |
| **Socket.io** | WebSocket server |
| **JWT** | Authentication |
| **Zod** | Validation |
| **Cloudinary** | Media storage |
| **bcryptjs** | Password hashing |

### AI Service (`AI-Service/`)
| Technology | Purpose |
|------------|---------|
| **FastAPI** | Python web framework |
| **LangChain** | AI orchestration |
| **Google Gemini** | Vision & fast analysis |
| **OpenAI GPT-4o** | Creative text generation |
| **MediaPipe** | Face/gesture detection |
| **OpenCV** | Image processing |
| **Redis** | Session/memory storage |
| **Motor** | Async MongoDB |

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** v18+ 
- **Python** 3.10+
- **MongoDB** (local or Atlas)
- **Redis** (optional, for production)
- **API Keys**: Gemini AI, OpenAI (optional)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/heartspeak-ai.git
cd heartspeak-ai
```

### 2ï¸âƒ£ Setup the Backend Server

```bash
cd Server
npm install

# Create environment file
cp .env.example .env
```

Edit `.env` with your configuration:

```env
NODE_ENV=development
PORT=5000
DATABASE_URL=mongodb://localhost:27017/heartspeak
JWT_ACCESS_SECRET=your_access_secret_here
JWT_REFRESH_SECRET=your_refresh_secret_here
JWT_ACCESS_EXPIRES_IN=1d
JWT_REFRESH_EXPIRES_IN=365d
BCRYPT_SALT_ROUNDS=12
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_api_key
CLOUDINARY_API_SECRET=your_api_secret
PYTHON_AI_SERVICE_URL=http://localhost:8000
```

Start the server:

```bash
npm run dev
```

### 3ï¸âƒ£ Setup the AI Service

```bash
cd AI-Service

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Create environment file
cp .env.example .env
```

Edit `.env`:

```env
GEMINI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key
MONGODB_URL=mongodb://localhost:27017/heartspeak
REDIS_URL=redis://localhost:6379
NODE_SERVER_URL=http://localhost:5000
```

Start the AI service:

```bash
uvicorn app.main:app --reload --port 8000
```

### 4ï¸âƒ£ Setup the Frontend Client

```bash
cd client
npm install

# Create environment file (if needed)
# Add your environment variables
```

Start the development server:

```bash
npm run dev
```

### 5ï¸âƒ£ Access the Application

Open your browser and navigate to:
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5000
- **AI Service API**: http://localhost:8000/docs (Swagger UI)

---

## ğŸ“¡ API Reference

### Node.js Server Endpoints

#### Authentication
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/auth/register` | Register new user |
| `POST` | `/api/v1/auth/login` | User login |
| `POST` | `/api/v1/auth/refresh-token` | Refresh access token |
| `POST` | `/api/v1/auth/change-password` | Change password |

### Python AI Service Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/emotion/analyze` | Analyze facial emotions from image |
| `POST` | `/api/v1/pattern/analyze` | Analyze pattern features |
| `POST` | `/api/v1/pattern/interpret` | Interpret pattern with context |
| `POST` | `/api/v1/chat/generate` | Generate emotion-to-text |
| `POST` | `/api/v1/avatar/suggest` | Get avatar suggestions |
| `POST` | `/api/v1/avatar/build-profile` | Build/update avatar profile |

---

## ğŸ”Œ Socket.io Events

### Video Call Events
| Event | Direction | Description |
|-------|-----------|-------------|
| `call:initiate` | Client â†’ Server | Start a call |
| `call:incoming` | Server â†’ Client | Notify recipient |
| `call:accept` | Client â†’ Server | Accept call |
| `call:reject` | Client â†’ Server | Reject call |
| `call:signal` | Bidirectional | WebRTC signaling |
| `call:emotion` | Server â†’ Client | Emotion analysis result |
| `call:end` | Bidirectional | End call |

### Chat Events
| Event | Direction | Description |
|-------|-----------|-------------|
| `chat:message` | Server â†’ Client | New emotion message |
| `chat:typing` | Bidirectional | Typing indicator |
| `chat:reaction` | Bidirectional | Message reaction |

---

## ğŸ¤– AI Strategy

HeartSpeak uses a smart routing system to choose the best AI for each task:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI REQUEST ROUTING                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Has Image/Video? â”€â”€YESâ”€â”€â–º ğŸŸ¦ GEMINI (Vision tasks)    â”‚
â”‚        â”‚                                                â”‚
â”‚       NO                                                â”‚
â”‚        â”‚                                                â”‚
â”‚  Needs Creativity? â”€YESâ”€â”€â–º ğŸŸ© GPT-4o (Rich text gen)   â”‚
â”‚        â”‚                                                â”‚
â”‚       NO                                                â”‚
â”‚        â”‚                                                â”‚
â”‚  Simple Task? â”€â”€â”€â”€â”€â”€YESâ”€â”€â–º ğŸŸ¦ GEMINI FLASH (Fast)      â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Use Case | Best AI | Reasoning |
|----------|---------|-----------|
| Real-time video analysis | Gemini Flash | Fast, cost-effective, multimodal |
| Pattern recognition | Gemini Flash | Superior visual understanding |
| Emotion text generation | GPT-4o | Nuanced, empathetic writing |
| Avatar conversations | GPT-4o | Personality consistency |
| Quick classification | Gemini Flash | Low latency |

---

## ğŸ§ª Testing Video Calls

See the [VIDEO_CALL_TEST_GUIDE.md](./VIDEO_CALL_TEST_GUIDE.md) for comprehensive testing instructions.

Quick test:
1. Open http://localhost:3000/test-call in two browser tabs
2. Register/login with different users
3. Initiate a call from one tab
4. Accept in the other tab
5. Observe emotion detection overlays

---

## ğŸš¢ Deployment

### Recommended Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION SETUP                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚   Cloudflare (CDN/DNS)                                  â”‚
â”‚        â”‚                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚            â”‚            â”‚           â”‚              â”‚
â”‚   â–¼            â–¼            â–¼           â–¼              â”‚
â”‚ Vercel     Railway      Railway     MongoDB            â”‚
â”‚ (Next.js)  (Node.js)    (Python)    Atlas              â”‚
â”‚                                                         â”‚
â”‚              â”‚            â”‚                            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â–º Redis (Upstash)         â”‚
â”‚                              + Cloudinary              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“œ Scripts Reference

### Server
```bash
npm run dev      # Development with hot reload
npm run build    # Build for production
npm start        # Start production server
npm run lint     # Run ESLint
npm run format   # Format with Prettier
```

### AI Service
```bash
uvicorn app.main:app --reload --port 8000  # Development
uvicorn app.main:app --host 0.0.0.0 --port 8000  # Production
```

### Client
```bash
npm run dev      # Development server
npm run build    # Production build
npm start        # Start production
npm run lint     # Run ESLint
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Follow the modular architecture pattern
4. Add TypeScript types & Zod validation
5. Test Socket.io events manually
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the ISC License.

---

## ğŸ™ Acknowledgments

- **MediaPipe** for face/gesture detection
- **LangChain** for AI orchestration
- **Google Gemini** & **OpenAI** for AI capabilities
- All contributors and the open-source community

---

<p align="center">
  <strong>HeartSpeak AI</strong> â€” Empowering communication from the heart â¤ï¸
</p>

<p align="center">
  <sub>Built with ğŸ’œ for those who speak without words</sub>
</p>

